<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Welcome!</title>
  
  <subtitle>Joseph的个人博客</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-10-08T10:25:40.628Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Joseph</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>git的使用</title>
    <link href="http://yoursite.com/2019/10/08/git%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <id>http://yoursite.com/2019/10/08/git的使用/</id>
    <published>2019-10-08T10:08:47.000Z</published>
    <updated>2019-10-08T10:25:40.628Z</updated>
    
    <content type="html"><![CDATA[<h4 id="新建文件夹，查看当前路径"><a href="#新建文件夹，查看当前路径" class="headerlink" title="新建文件夹，查看当前路径"></a>新建文件夹，查看当前路径</h4><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir learngit</span><br><span class="line">$ cd learngit</span><br><span class="line">$ pwd</span><br><span class="line">-----------------------</span><br><span class="line">/Users/michael/learngit</span><br></pre></td></tr></table></figure><h4 id="初始化-init"><a href="#初始化-init" class="headerlink" title="初始化-init"></a>初始化-init</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ git init</span><br><span class="line">-----------------------</span><br><span class="line">Initialized empty Git repository in /Users/michael/learngit/.git/</span><br></pre></td></tr></table></figure><a id="more"></a><ul><li><p>目录默认是隐藏的，用ls -ah命令就可以看见</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ls -ah</span><br></pre></td></tr></table></figure></li><li><p>创建文件(按esc后键入:wq退出)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vi readme.txt</span><br></pre></td></tr></table></figure></li></ul><h4 id="添加文件-add"><a href="#添加文件-add" class="headerlink" title="添加文件-add"></a>添加文件-add</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git add readme.txt</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ git add -A</span><br></pre></td></tr></table></figure><h4 id="提交文件-commit"><a href="#提交文件-commit" class="headerlink" title="提交文件-commit"></a>提交文件-commit</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ git commit -m &quot;wrote a readme file&quot;</span><br><span class="line">------------------------</span><br><span class="line">[master (root-commit) eaadf4e] wrote a readme file</span><br><span class="line"> 1 file changed, 2 insertions(+)</span><br><span class="line"> create mode 100644 readme.txt</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;新建文件夹，查看当前路径&quot;&gt;&lt;a href=&quot;#新建文件夹，查看当前路径&quot; class=&quot;headerlink&quot; title=&quot;新建文件夹，查看当前路径&quot;&gt;&lt;/a&gt;新建文件夹，查看当前路径&lt;/h4&gt;&lt;figure class=&quot;highlight asciidoc&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ mkdir learngit&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ cd learngit&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;$ pwd&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;-----------------------&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;/Users/michael/learngit&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h4 id=&quot;初始化-init&quot;&gt;&lt;a href=&quot;#初始化-init&quot; class=&quot;headerlink&quot; title=&quot;初始化-init&quot;&gt;&lt;/a&gt;初始化-init&lt;/h4&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ git init&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;-----------------------&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Initialized empty Git repository in /Users/michael/learngit/.git/&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>初识Scrapy</title>
    <link href="http://yoursite.com/2019/10/08/%E5%88%9D%E8%AF%86Scrapy/"/>
    <id>http://yoursite.com/2019/10/08/初识Scrapy/</id>
    <published>2019-10-08T07:25:50.000Z</published>
    <updated>2019-10-08T09:08:34.983Z</updated>
    
    <content type="html"><![CDATA[<h4 id="什么是Scrapy？"><a href="#什么是Scrapy？" class="headerlink" title="什么是Scrapy？"></a>什么是Scrapy？</h4><p><code>Scrapy</code>使用 <code>Python</code> 实现的一个开源爬虫框架，<code>Scrapy</code>基于 <code>twisted</code>这个高性能的事件驱动网络引擎框架，<code>Scrapy</code>爬虫拥有很高的性能。</p><ol><li><code>Scrapy</code>内置数据提取器（<code>Selector</code>），支持<code>XPath</code>和 <code>Scrapy</code>自己的 <code>CSS Selector</code>语法</li><li>并且支持正则表达式，方便从网页提取信息。</li><li>交互式的命令行工具，方便测试 <code>Selector</code> 和 <code>debugging</code>爬虫</li><li>支持将数据导出为 <code>JSON，CSV，XML</code>格式。</li><li>可推展性强，运行自己编写特定功能的插件</li><li>内置了很多拓展和中间件用于处理：<ul><li><code>cookies</code>和 <code>session</code></li><li><code>HTTP</code>的压缩，认证，缓存</li><li><code>robots.txt</code></li><li>爬虫深度限制</li></ul></li></ol><a id="more"></a><h4 id="Scrapy流程图"><a href="#Scrapy流程图" class="headerlink" title="Scrapy流程图"></a>Scrapy流程图</h4><img src="/2019/10/08/初识Scrapy/GkjK7BGIB0.png" title="This is an example image"><p>其中：</p><ul><li><code>Scrapy Engine(引擎)</code>: 负责<code>Spider</code>、<code>ItemPipeline</code>、<code>Downloader</code>、<code>Scheduler</code>中间的通讯，信号、数据传递等。</li><li><code>Scheduler(调度器)</code>: 它负责接受引擎发送过来的Request请求，并按照一定的方式进行整理排列，入队，当<code>引擎</code>需要时，交还给<code>引擎</code>。</li><li><code>Downloader（下载器）</code>：负责下载<code>Scrapy Engine(引擎)</code>发送的所有Requests请求，并将其获取到的Responses交还给<code>Scrapy Engine(引擎)</code>，由<code>引擎</code>交给<code>Spider</code>来处理，</li><li><code>Spider（爬虫）</code>：它负责处理所有Responses,从中分析提取数据，获取Item字段需要的数据，并将需要跟进的URL提交给<code>引擎</code>，再次进入<code>Scheduler(调度器)</code>，</li><li><code>Item Pipeline(管道)</code>：它负责处理<code>Spider</code>中获取到的Item，并进行进行后期处理（详细分析、过滤、存储等）的地方.</li><li><code>Downloader Middlewares（下载中间件）</code>：你可以当作是一个可以自定义扩展下载功能的组件。</li><li><code>Spider Middlewares（Spider中间件）</code>：你可以理解为是一个可以自定扩展和操作<code>引擎</code>和<code>Spider</code>中间<code>通信</code>的功能组件（比如进入<code>Spider</code>的Responses;和从<code>Spider</code>出去的Requests）</li></ul><h4 id="制作-Scrapy-爬虫-的步骤"><a href="#制作-Scrapy-爬虫-的步骤" class="headerlink" title="制作 Scrapy 爬虫 的步骤?"></a>制作 Scrapy 爬虫 的步骤?</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">新建项目(scrapy startproject xxx)：新建一个新的爬虫项目</span><br><span class="line">明确目标（编写items.py）：明确你想要抓取的目标</span><br><span class="line">制作爬虫（spiders/xxspider.py）：制作爬虫开始爬取网页</span><br><span class="line">存储内容（pipelines.py）：设计管道存储爬取内容</span><br></pre></td></tr></table></figure><h4 id="如何安装Scrapy"><a href="#如何安装Scrapy" class="headerlink" title="如何安装Scrapy?"></a>如何安装Scrapy?</h4><h4 id="在windows系统下安装Scrapy"><a href="#在windows系统下安装Scrapy" class="headerlink" title="在windows系统下安装Scrapy?"></a>在windows系统下安装Scrapy?</h4><p>在windows 64bit系统下安装Scrapy需要安装以下依赖库：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">pip install wheel</span><br><span class="line">lxml-4.2.1-cp36-cp36m-win_amd64.whl</span><br><span class="line">pyOpenSSL-17.5.0-py2.py3-none-any.whl</span><br><span class="line">pywin32-221.win-amd64-py3.6.exe</span><br><span class="line">Twisted-17.9.0-cp36-cp36m-win_amd64.whl</span><br><span class="line">pip install scrapy</span><br></pre></td></tr></table></figure><h4 id="在linux下安装Scrapy"><a href="#在linux下安装Scrapy" class="headerlink" title="在linux下安装Scrapy"></a>在linux下安装Scrapy</h4><p>系统版本为ubuntu 16.04</p><figure class="highlight q"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-<span class="built_in">get</span> install build-essential python3-<span class="built_in">dev</span> libssl-<span class="built_in">dev</span> libffi-<span class="built_in">dev</span> libxml2 libxml2-<span class="built_in">dev</span> libxslt1-<span class="built_in">dev</span> zlib1g-<span class="built_in">dev</span></span><br><span class="line">pip install scrapy</span><br></pre></td></tr></table></figure><h4 id="Scrapy文件结构"><a href="#Scrapy文件结构" class="headerlink" title="Scrapy文件结构"></a>Scrapy文件结构</h4><p>我们在windows命令行模式下输入以下命令创建Scrapy项目：</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">scrapy </span>startproject 项目名称</span><br></pre></td></tr></table></figure><p>可以看到创建了以下文件：</p><img src="/2019/10/08/初识Scrapy/C8bHEFJIJ3.png" title="This is an example image"><p>其中：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scrapy<span class="selector-class">.cfg</span> ：项目的配置文件</span><br><span class="line">xxSpider/ ：项目的Python模块，将会从这里引用代码</span><br><span class="line">xxSpider/items<span class="selector-class">.py</span> ：项目的目标文件</span><br><span class="line">xxSpider/pipelines<span class="selector-class">.py</span> ：项目的管道文件</span><br><span class="line">xxSpider/settings<span class="selector-class">.py</span> ：项目的设置文件</span><br><span class="line">xxSpider/spiders/ ：存储爬虫代码目录</span><br></pre></td></tr></table></figure><h4 id="Scrapy单文件demo"><a href="#Scrapy单文件demo" class="headerlink" title="Scrapy单文件demo"></a>Scrapy单文件demo</h4><p>创建完Scrapy项目，还是要上手实验一下才能更好的理解，所以我根据之前我在楼+课程中的学习笔记写了一个Scrapy单文件Demo，使用这个单文件Demo能快速爬取实验楼全部课程信息。<br>首先看下单文件的内容结构：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ShiyanlouCoursesSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    <span class="string">""" 所有 scrapy 爬虫需要写一个 Spider 类，这个类要继承 scrapy.Spider 类。在这个类中定义要请求的网站和链接、如何从返回的网页提取数据等等。</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># 爬虫标识符号，在 scrapy 项目中可能会有多个爬虫，name 用于标识每个爬虫，不能相同</span></span><br><span class="line">    name = <span class="string">'shiyanlou-courses'</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">""" 需要返回一个可迭代的对象，迭代的元素是scrapy.Request对象，可迭代对象可以是一个列表或者迭代器，这样 scrapy 就知道有哪些网页需要爬取了。scrapy.Request接受一个 url 参数和一个 callback 参数，url 指明要爬取的网页，callback 是一个回调函数用于处理返回的网页，通常是一个提取数据的 parse 函数。</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="string">""" 这个方法作为 `scrapy.Request` 的 callback，在里面编写提取数据的代码。scrapy 中的下载器会下载 `start_reqeusts` 中定义的每个 `Request` 并且结果封装为一个 response 对象传入这个方法。</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>因为实验楼的网页结构还是很简单的，所以解析部分就不做赘述，直接上单文件完整代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ShiyanlouCoursesSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="comment"># 课程列表页面 url 模版</span></span><br><span class="line">    url_tmpl = <span class="string">'https://www.shiyanlou.com/courses/?category=all&amp;course_type=all&amp;fee=all&amp;tag=all&amp;page=&#123;&#125;'</span></span><br><span class="line">    <span class="comment"># 所有要爬取的页面</span></span><br><span class="line">    urls = (url_tmpl.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">23</span>))</span><br><span class="line">    <span class="comment"># 返回一个生成器，生成 Request 对象，生成器是可迭代对象</span></span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(url=url, callback=self.parse)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">    <span class="comment"># 遍历每个课程的 div.course-body</span></span><br><span class="line">    <span class="keyword">for</span> course <span class="keyword">in</span> response.css(<span class="string">'div.course-body'</span>):</span><br><span class="line">        <span class="comment"># 使用 css 语法对每个 course 提取数据</span></span><br><span class="line">        <span class="keyword">yield</span> &#123;</span><br><span class="line">            <span class="comment"># 课程名称</span></span><br><span class="line">            <span class="string">'name'</span>: course.css(<span class="string">'div.course-name::text'</span>).extract_first(),</span><br><span class="line">            <span class="comment"># 课程描述</span></span><br><span class="line">            <span class="string">'description'</span>: course.css(<span class="string">'div.course-desc::text'</span>).extract_first(),</span><br><span class="line">            <span class="comment"># 课程类型，实验楼的课程有免费，会员，训练营三种，免费课程并没有字样显示，也就是说没有 span.pull-right 这个标签，没有这个标签就代表时免费课程，使用默认值 `免费｀就可以了。</span></span><br><span class="line">            <span class="string">'type'</span>: course.css(<span class="string">'div.course-footer span.pull-right::text'</span>).extract_first(default=<span class="string">'Free'</span>),</span><br><span class="line">            <span class="comment"># 注意 // 前面的 .，没有点表示整个文档所有的 div.course-body，有 . 才表示当前迭代的这个 div.course-body</span></span><br><span class="line">               <span class="string">'students'</span>: course.xpath(<span class="string">'.//span[contains(@class, "pull-left")]/text()[2]'</span>).re_first(<span class="string">'[^\d]*(\d*)[^\d]*'</span>)</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><p>保存文件，使用scrapy runspider xx.py -o data.json运行代码，这里使用 -o参数将结果输出为json格式。</p>]]></content>
    
    <summary type="html">
    
      &lt;h4 id=&quot;什么是Scrapy？&quot;&gt;&lt;a href=&quot;#什么是Scrapy？&quot; class=&quot;headerlink&quot; title=&quot;什么是Scrapy？&quot;&gt;&lt;/a&gt;什么是Scrapy？&lt;/h4&gt;&lt;p&gt;&lt;code&gt;Scrapy&lt;/code&gt;使用 &lt;code&gt;Python&lt;/code&gt; 实现的一个开源爬虫框架，&lt;code&gt;Scrapy&lt;/code&gt;基于 &lt;code&gt;twisted&lt;/code&gt;这个高性能的事件驱动网络引擎框架，&lt;code&gt;Scrapy&lt;/code&gt;爬虫拥有很高的性能。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;Scrapy&lt;/code&gt;内置数据提取器（&lt;code&gt;Selector&lt;/code&gt;），支持&lt;code&gt;XPath&lt;/code&gt;和 &lt;code&gt;Scrapy&lt;/code&gt;自己的 &lt;code&gt;CSS Selector&lt;/code&gt;语法&lt;/li&gt;
&lt;li&gt;并且支持正则表达式，方便从网页提取信息。&lt;/li&gt;
&lt;li&gt;交互式的命令行工具，方便测试 &lt;code&gt;Selector&lt;/code&gt; 和 &lt;code&gt;debugging&lt;/code&gt;爬虫&lt;/li&gt;
&lt;li&gt;支持将数据导出为 &lt;code&gt;JSON，CSV，XML&lt;/code&gt;格式。&lt;/li&gt;
&lt;li&gt;可推展性强，运行自己编写特定功能的插件&lt;/li&gt;
&lt;li&gt;内置了很多拓展和中间件用于处理：&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cookies&lt;/code&gt;和 &lt;code&gt;session&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;HTTP&lt;/code&gt;的压缩，认证，缓存&lt;/li&gt;
&lt;li&gt;&lt;code&gt;robots.txt&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;爬虫深度限制&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://yoursite.com/2019/09/29/hello-world/"/>
    <id>http://yoursite.com/2019/09/29/hello-world/</id>
    <published>2019-09-29T09:06:02.549Z</published>
    <updated>2019-09-29T09:06:02.550Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
    
  </entry>
  
</feed>
